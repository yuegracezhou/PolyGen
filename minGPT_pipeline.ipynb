{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "888d8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "\n",
    "# 如果没有 gibrat 但有 gilbrat，就做一个别名\n",
    "if not hasattr(ss, \"gibrat\") and hasattr(ss, \"gilbrat\"):\n",
    "    ss.gibrat = ss.gilbrat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5593892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "/Users/yuezhou/opt/anaconda3/envs/env_polygen_mingpt/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/Users/yuezhou/opt/anaconda3/envs/env_polygen_mingpt/lib/python3.8/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "from rdkit import Chem\n",
    "import sys\n",
    "from deepchem.feat.smiles_tokenizer import SmilesTokenizer\n",
    "from minGPT.pipeline import minGPT\n",
    "# minGPT including: data_preprocessing, load_model, train, generate, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5504b28-0785-4b35-b9f8-f63ca2f0bcc8",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b36bb88-5c31-47ab-bbfc-9f283898c5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_col: mol_smiles\n",
      "length: 5\n",
      "block_size: 64\n",
      "train_test_split: (0.8, 0.2)\n",
      "task: conditional\n",
      "file_path: minGPT/htp_md.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = minGPT()\n",
    "data_config = pipeline.get_default_data_config()\n",
    "data_config.file_path = \"minGPT/htp_md.csv\"\n",
    "data_config.block_size = 64\n",
    "\n",
    "print(data_config)\n",
    "train_dataset, test_dataset = pipeline.data_preprocessing(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66681958-a1f1-4fcd-8216-e2a15fc54c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bdf2a24-8cd4-41c7-bedd-07525412f532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.12M\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model_config = pipeline.get_default_model_config()\n",
    "model_config.model_type = 'gpt-nano'\n",
    "model_config.vocab_size = train_dataset.get_vocab_size()\n",
    "model_config.block_size = train_dataset.get_block_size()\n",
    "pipeline.load_model(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8f6b2e-7ba9-4ee1-8a86-c6221893617f",
   "metadata": {},
   "source": [
    "## Training configuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b97415-56ac-4b8d-bda6-214d93ab8e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Training configuration--------\n",
      "device: auto\n",
      "num_workers: 0\n",
      "max_iters: None\n",
      "batch_size: 64\n",
      "learning_rate: 0.0005\n",
      "betas: (0.9, 0.95)\n",
      "weight_decay: 0.1\n",
      "grad_norm_clip: 1.0\n",
      "model: None\n",
      "call_back: None\n",
      "pretrain: None\n",
      "\n",
      "auto\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "train_config = pipeline.get_default_train_config()\n",
    "print(\"--------Training configuration--------\")\n",
    "print(train_config)\n",
    "\n",
    "\n",
    "print(train_config.device)\n",
    "train_config.max_iters = 10000\n",
    "train_config.ckpt_path = \"./minGPT/ckpts/\"\n",
    "# Uncomment the following line if load from pre-trained model chkpts\n",
    "train_config.pretrain = \"./ckpts/10000.pt\"\n",
    "\n",
    "## Define call back function\n",
    "def batch_end_callback(trainer):\n",
    "    if trainer.iter_num % 100 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}, val loss {trainer.loss_val.item():.5f}\")\n",
    "\n",
    "train_config.call_back = batch_end_callback\n",
    "# Uncomment the following line to start training\n",
    "# loss = pipeline.train(train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b47532-ba38-4536-9161-d71a2f8489d3",
   "metadata": {},
   "source": [
    "## Generating with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b13fe-9653-4f6b-9d9b-cc4a00f51eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpts_path: None\n",
      "num_samples: 100\n",
      "temperature: 1.0\n",
      "task: conditional\n",
      "ckpt_path: ./minGPT/ckpts/10000.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate_config = pipeline.get_default_generate_config()\n",
    "# generate_config.ckpt_path = \"./minGPT/ckpts/10000.pt\"\n",
    "# assert generate_config.task == data_config.task\n",
    "# print(generate_config)\n",
    "\n",
    "# results = pipeline.generate(generate_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3e543-184d-40f6-a662-2f5aae481ea1",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "Calculate the scores for \n",
    "**uniqueness, novelty, validity, synthesibility, similarity, diversity**, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c824f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.95, 0.5800000000000001, 0.89, 0.9565217391304348, 0.25568710931368277, 0.704277235149268)\n"
     ]
    }
   ],
   "source": [
    "# print(pipeline.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d61d53",
   "metadata": {},
   "source": [
    "1. Uniqueness:\n",
    "Measures how many of the generated molecules are not duplicates of each other.\n",
    "\n",
    "    Uniqueness = 1 - number of duplicated molecules​ / total number of generated molecules\n",
    "\n",
    "    A higher value (closer to 1) means the model is generating more diverse, non-repetitive molecules.\n",
    "\n",
    "2. Novelty: \n",
    "Measures how many of the generated molecules are not seen in the training set.\n",
    "\n",
    "    For each generated SMILES, check if it also appears in the training set (check_novelty).\n",
    "\n",
    "    1) If it appears in the training set -> label as “In the original data set”\n",
    "\n",
    "    2) Otherwise -> label as “novel”\n",
    "\n",
    "    Novelty = 1 - number of molecules found in the training set​ / total number of generated molecules\n",
    "\n",
    "3. Validity:\n",
    "Measures how many generated SMILES correspond to chemically valid and structurally correct molecules.\n",
    "\n",
    "    Use RDKit (validate_mol) to check:\n",
    "\n",
    "    1) Whether the SMILES can be parsed by Chem.MolFromSmiles().\n",
    "\n",
    "    2) Whether the terminal atoms (Cu, Au) have exactly one bond.\n",
    "\n",
    "    3) Whether the molecule contains exactly one [Cu] and one [Au] atom (two endpoints). Use has_two_ends() to explicitly label molecules with both endpoints.\n",
    "\n",
    "    Count how many satisfy both conditions:\n",
    "\n",
    "    1) validity == 'ok'\n",
    "\n",
    "    2) has_two_ends == True\n",
    "\n",
    "    Validity = number of valid molecules with two ends / total number of generated molecules\n",
    "\n",
    "4. Synthesizability:\n",
    "Estimates how feasible it would be to chemically synthesize the generated molecules.\n",
    "\n",
    "    Compute the Synthetic Accessibility (SA) score for each valid molecule using calculateScore(mol). Estimating synthesis difficulty based on molecular rarity.\n",
    "\n",
    "    ranges from 1 (easy to synthesize) to 10 (hard to synthesize). Define “synthesizable” molecules as those with SA < 5\n",
    "\n",
    "5. Similarity:\n",
    "Measures how similar the generated molecules are to those in the training set.\n",
    "\n",
    "    Compute Morgan fingerprints (radius = 2, 2048 bits) for both training and generated molecules.\n",
    "\n",
    "    For each generated molecule: Compute Tanimoto similarity with all molecules in the training set. Take the average of these similarity scores.\n",
    "\n",
    "    Finally, take the overall mean of all generated molecules’ similarity values:\n",
    "\n",
    "6. Diversity:\n",
    "Quantifies how structurally different the generated molecules are from each other.\n",
    "\n",
    "    Compute pairwise Tanimoto similarity among all generated molecules.\n",
    "\n",
    "    Higher diversity means the generated set spans a wider range of chemical space.\n",
    "\n",
    "    Diversity = 1 − average pairwise Tanimoto similarity among generated molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5ff14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O=C([Au])OCCN(CCOC(=O)O)CO[Cu]',\n",
       " 'CN(CCO[Cu])CCNCCOC(=O)[Au]',\n",
       " 'O=C([Au])OCCCNCCCCO[Cu]',\n",
       " 'CC(CNCCN(C)CCO[Cu])OC(=O)[Au]',\n",
       " 'O=C([Au])NCCNCCNCCN[Cu]',\n",
       " 'N#CCN(CCC#O)CC(OC(=O)[Au])O[Cu]',\n",
       " 'CN(CC(=O)N(C)CCO[Cu])CCOC(=O)[Au]',\n",
       " 'CCN(CC)CC(C(CO[Cu])OC(=O)[Au])OC',\n",
       " 'CN(C)CCCN(CCN[Cu])C(=O)CNC(=O)[Au]',\n",
       " 'CCCN(CCO[Cu])CCOC(=O)[Au]']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a9f9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COC(=O)CN(CCNC(=O)[Au])CCO[Cu]',\n",
       " 'C=CCN(CCCO[Cu])CCOC(=O)[Au]',\n",
       " 'O=C([Au])OCCCCNCCCCO[Cu]',\n",
       " 'COCC(CNCCCOC(=O)[Au])O[Cu]',\n",
       " 'O=C(COCCO[Cu])NCCOC(=O)[Au]',\n",
       " 'O=C(CCN[Cu])NCCOCCOC(=O)[Au]',\n",
       " 'C=CCCCCN(C)CC(CO[Cu])OC(=O)[Au]',\n",
       " 'O=C([Au])OCCNCCO[Cu]',\n",
       " 'CC(C)C(COC)NCC(CNC(=O)[Au])O[Cu]',\n",
       " 'CC(CCO[Cu])N(C)CCCCCOC(=O)[Au]']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_config = pipeline.get_default_generate_config()\n",
    "generate_config.ckpt_path = \"./minGPT/ckpts/10000.pt\"\n",
    "\n",
    "generate_config.target_property_value = 9   # 高导电\n",
    "generate_config.num_samples = 100\n",
    "\n",
    "high_results = pipeline.generate(generate_config)\n",
    "high_results[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84f3e163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COC(CO[Cu])N(C)CC(C)O[Cu])OC(=O)[Au]',\n",
       " 'NC(CN[Cu])NC(=O)[Au]',\n",
       " 'C#CC(C)(COC(=O)[Au])C(C)C(C)O[Cu]',\n",
       " 'CC(F)CC(N[Cu])C(=O)NCCCOC(=O)[Au]',\n",
       " 'CNC(=O)C(CCO[Cu])NC(=O)[Au]',\n",
       " 'CC(CNC(=O)[Au])N(C)CO[Cu]',\n",
       " 'C#CCN(CCCOC(=O)[Au])CCC(C)O[Cu]',\n",
       " 'CC(NC(=O)[Au])C(=O)NCCNCCO[Cu]',\n",
       " 'NC(=O)C(NC(=O)[Au])NCC(=O)O)O[Cu]',\n",
       " 'CCCC(C)(O[Cu])C(C)COC(=O)[Au]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_config_low = pipeline.get_default_generate_config()\n",
    "generate_config_low.ckpt_path = \"./minGPT/ckpts/10000.pt\"\n",
    "\n",
    "generate_config_low.target_property_value = 8   # 低导电\n",
    "generate_config_low.num_samples = 100\n",
    "\n",
    "low_results = pipeline.generate(generate_config_low)\n",
    "low_results[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "560a58af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 保存高导电\n",
    "with open(\"generated_high.json\", \"w\") as f:\n",
    "    json.dump(high_results, f)\n",
    "\n",
    "# 保存低导电\n",
    "with open(\"generated_low.json\", \"w\") as f:\n",
    "    json.dump(low_results, f)\n",
    "\n",
    "print(\"Saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_polygen_mingpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
